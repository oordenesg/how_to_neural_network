{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Neural_Network_Classification_Example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZDq2nwZp2dv"
      },
      "source": [
        "## Classification Exercises\n",
        "\n",
        "### Introduction\n",
        "\n",
        "In this exercise we will learn the architecture of a neural network, the parameters of a neural network and how they change with changing architecture and the hyperparameter tuning. \n",
        "\n",
        "We encourage you to work with other hyperparameters as well like learning rate, number of layers, activation functions etc. \n",
        "\n",
        "The Notebook is divided in three parts: Building the Model, Reading the dataset and Hyperparameters. It contains five sesctions in total and one additional optional exercise:\n",
        "\n",
        "### Part 1: Building the model\n",
        "Below we define a function to built a neural network model using TensorFlow Keras. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mhZ0xlMRqO6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "def built_model(input_shape, n_hidden, nb_classes, optimizer='SGD'):\n",
        "  '''\n",
        "  input_shape: The number of inputs to the neural network\n",
        "  n_hidden: Number of hidden neurons in the hidden layers\n",
        "  nb_classes: Number of neurons in the output layer\n",
        "  optimizer: The optimizer used to train the model. \n",
        "  By default we use Stochastic Gradient Descent.\n",
        "  \n",
        "  Returns:\n",
        "  The function returns A model with loss and optimizer defined\n",
        "  '''  \n",
        "  model = tf.keras.models.Sequential()\n",
        "  ## First Hidden layer  \n",
        "  model.add(keras.layers.Dense(n_hidden,\n",
        "       input_shape=(input_shape,),\n",
        "       name='dense_layer', activation='relu'))\n",
        "    \n",
        "  ## Second Hidden Layer\n",
        "  model.add(keras.layers.Dense(n_hidden,\n",
        "        name='dense_layer_2', activation='relu'))\n",
        "    \n",
        "  ## Output Layer  \n",
        "  model.add(keras.layers.Dense(nb_classes,\n",
        "        name='dense_layer_3', activation='softmax'))\n",
        "    \n",
        "  ## Define loss and optimizer \n",
        "  model.compile(optimizer=optimizer, \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBfRdV8ARuCe"
      },
      "source": [
        "# Defining the structure of our neural network\n",
        "INPUT_SHAPE = 5\n",
        "N_HIDDEN = 10\n",
        "NB_CLASSES = 2  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s00urUTcqfZR",
        "outputId": "c951182a-3132-49f0-d8d3-1f04e0ca8461"
      },
      "source": [
        "model = built_model(INPUT_SHAPE, N_HIDDEN,NB_CLASSES)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer (Dense)          (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_layer_2 (Dense)        (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_layer_3 (Dense)        (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 192\n",
            "Trainable params: 192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTccrPMNyZF5"
      },
      "source": [
        "<a id='ex_2'></a>\n",
        "**Here, it is important to note that our neural network has 192 parameters. As the number of networks increases, so does the complexity and execution time. Now, let's visualize the summary of the model created**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4OteoBfx_QH",
        "outputId": "34a82563-a32d-446e-8937-5d5829486564"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer (Dense)          (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_layer_2 (Dense)        (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_layer_3 (Dense)        (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 192\n",
            "Trainable params: 192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qeqEE5A3MQl"
      },
      "source": [
        "### Part 2: Reading the dataset\n",
        "\n",
        "We will continue with the MNIST dataset. \n",
        "\n",
        "###### Just run the cells in this part of the notebook. Do not change anything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3OEjwzLyBoO",
        "outputId": "67f0d773-362c-4f75-9040-5d1af9f32c1f"
      },
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94uZnloL4-lB"
      },
      "source": [
        "# Processing the data\n",
        "assert(len(X_train.shape)==3), \"The input data is not of the right shape\"\n",
        "RESHAPED = X_train.shape[1]*X_train.shape[2]\n",
        "\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJIMT6sT5Wtd",
        "outputId": "1ec3c0f3-2d59-4fcc-84a8-41cbe10b3830"
      },
      "source": [
        "# Data Normalization\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIRrNUTj4h_R"
      },
      "source": [
        "For the MNIST dataset the number of input and number of output units are fixed. However we can choose different values of hidden units. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si1FflpL3_hj"
      },
      "source": [
        "INPUT_SHAPE = RESHAPED\n",
        "NB_CLASSES = len(set(Y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISwN58Q48a03"
      },
      "source": [
        "# one-hot encode\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gjEx-hQ6Xsv"
      },
      "source": [
        "### Part 3: Hyperparameters\n",
        "\n",
        "<a id='ex_3'></a>\n",
        "The aim of this section is to understand the affect of changing number of hidden units on the model performance. Change the number of hidden units, and train the model. Compare the model performance in terms of accuracy. What do you understand from this?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qscy8jLk6BEA"
      },
      "source": [
        "# Task to do choose different values for number of hidden units (minimum five different values)\n",
        "N_HIDDEN = 10 #Choose a value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yG8aKH37krD",
        "outputId": "60303925-58a9-4cca-eb47-57692db0b8b6"
      },
      "source": [
        "## Do not change anything below\n",
        "model = built_model(INPUT_SHAPE,N_HIDDEN, NB_CLASSES)\n",
        "history = model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=128, epochs=50,\n",
        "\t\tverbose=1, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy: {:.2f} %'.format(test_acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "375/375 [==============================] - 4s 3ms/step - loss: 2.2050 - accuracy: 0.2115 - val_loss: 1.6894 - val_accuracy: 0.5091\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.4588 - accuracy: 0.5759 - val_loss: 0.8607 - val_accuracy: 0.8032\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.7964 - accuracy: 0.8013 - val_loss: 0.5601 - val_accuracy: 0.8568\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5658 - accuracy: 0.8490 - val_loss: 0.4604 - val_accuracy: 0.8749\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4834 - accuracy: 0.8647 - val_loss: 0.4121 - val_accuracy: 0.8872\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8818 - val_loss: 0.3861 - val_accuracy: 0.8913\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4042 - accuracy: 0.8859 - val_loss: 0.3672 - val_accuracy: 0.8959\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3825 - accuracy: 0.8923 - val_loss: 0.3538 - val_accuracy: 0.8989\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8971 - val_loss: 0.3434 - val_accuracy: 0.9014\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8967 - val_loss: 0.3358 - val_accuracy: 0.9048\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3539 - accuracy: 0.8979 - val_loss: 0.3271 - val_accuracy: 0.9078\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.9019 - val_loss: 0.3216 - val_accuracy: 0.9082\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.9055 - val_loss: 0.3161 - val_accuracy: 0.9110\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.9063 - val_loss: 0.3127 - val_accuracy: 0.9102\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3226 - accuracy: 0.9078 - val_loss: 0.3073 - val_accuracy: 0.9131\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3169 - accuracy: 0.9083 - val_loss: 0.3035 - val_accuracy: 0.9143\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3119 - accuracy: 0.9097 - val_loss: 0.2981 - val_accuracy: 0.9156\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3024 - accuracy: 0.9117 - val_loss: 0.2949 - val_accuracy: 0.9167\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3042 - accuracy: 0.9140 - val_loss: 0.2931 - val_accuracy: 0.9176\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3053 - accuracy: 0.9121 - val_loss: 0.2877 - val_accuracy: 0.9180\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2993 - accuracy: 0.9131 - val_loss: 0.2858 - val_accuracy: 0.9178\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2950 - accuracy: 0.9158 - val_loss: 0.2835 - val_accuracy: 0.9182\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2905 - accuracy: 0.9165 - val_loss: 0.2812 - val_accuracy: 0.9194\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2975 - accuracy: 0.9157 - val_loss: 0.2785 - val_accuracy: 0.9202\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2795 - accuracy: 0.9196 - val_loss: 0.2769 - val_accuracy: 0.9216\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.9200 - val_loss: 0.2735 - val_accuracy: 0.9217\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2753 - accuracy: 0.9213 - val_loss: 0.2714 - val_accuracy: 0.9222\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.9234 - val_loss: 0.2715 - val_accuracy: 0.9221\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.9203 - val_loss: 0.2675 - val_accuracy: 0.9234\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2744 - accuracy: 0.9201 - val_loss: 0.2653 - val_accuracy: 0.9247\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2687 - accuracy: 0.9202 - val_loss: 0.2641 - val_accuracy: 0.9247\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2677 - accuracy: 0.9220 - val_loss: 0.2631 - val_accuracy: 0.9241\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.9210 - val_loss: 0.2599 - val_accuracy: 0.9261\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.9268 - val_loss: 0.2588 - val_accuracy: 0.9268\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2595 - accuracy: 0.9243 - val_loss: 0.2593 - val_accuracy: 0.9259\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2567 - accuracy: 0.9261 - val_loss: 0.2558 - val_accuracy: 0.9264\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9250 - val_loss: 0.2537 - val_accuracy: 0.9277\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.9281 - val_loss: 0.2525 - val_accuracy: 0.9282\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2397 - accuracy: 0.9299 - val_loss: 0.2529 - val_accuracy: 0.9275\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.9300 - val_loss: 0.2504 - val_accuracy: 0.9275\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.9290 - val_loss: 0.2501 - val_accuracy: 0.9296\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2491 - accuracy: 0.9275 - val_loss: 0.2505 - val_accuracy: 0.9280\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.9307 - val_loss: 0.2471 - val_accuracy: 0.9296\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2338 - accuracy: 0.9317 - val_loss: 0.2480 - val_accuracy: 0.9312\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.9296 - val_loss: 0.2446 - val_accuracy: 0.9304\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2376 - accuracy: 0.9317 - val_loss: 0.2457 - val_accuracy: 0.9295\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2370 - accuracy: 0.9328 - val_loss: 0.2458 - val_accuracy: 0.9306\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2441 - accuracy: 0.9302 - val_loss: 0.2430 - val_accuracy: 0.9319\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2340 - accuracy: 0.9352 - val_loss: 0.2441 - val_accuracy: 0.9309\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2349 - accuracy: 0.9327 - val_loss: 0.2416 - val_accuracy: 0.9320\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.9306\n",
            "Test accuracy: 93.06 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WVLxc7I8C3L"
      },
      "source": [
        "N_HIDDEN = [10,20,30,40,50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehWEG9JY8IGX",
        "outputId": "dc1cbfd9-05ff-4a26-d6fb-fe775c8af58a"
      },
      "source": [
        "## Do not change anything below\n",
        "for i in range(0,len(N_HIDDEN)):\n",
        "  model = built_model(INPUT_SHAPE,N_HIDDEN[i], NB_CLASSES)\n",
        "  history = model.fit(X_train, Y_train,\n",
        "\t\t  batch_size=128, epochs=50,\n",
        "\t\t  verbose=0, validation_split=0.2)\n",
        "  # Evaluate the model\n",
        "  test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "  print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2995 - accuracy: 0.9195\n",
            "0.9194999933242798\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1899 - accuracy: 0.9430\n",
            "0.9430000185966492\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1650 - accuracy: 0.9523\n",
            "0.9523000121116638\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1452 - accuracy: 0.9563\n",
            "0.9563000202178955\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1478 - accuracy: 0.9548\n",
            "0.954800009727478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqfMXnlJA02g"
      },
      "source": [
        "<a id='ex_4'></a>\n",
        "### Part 4: Hyperparameters\n",
        "\n",
        "Let us now repeat the same after changing the batch size (minimum 5 different values). Compare the model performance in terms of accuracy. What do you understand from this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z0TctxjB0KA"
      },
      "source": [
        "**Answer** \n",
        "\n",
        "10: 91.94%\n",
        "20: 94.30%\n",
        "30: 95.23%\n",
        "40: 95.63%\n",
        "50: 91.94%\n",
        "\n",
        "The results show that as we increase the number of neurons, we will obtain better results. However, it does not mean that we have increased the number of neuons in the hidden layers abruptly as it could cause an overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXO0QZtS_mQ_"
      },
      "source": [
        "# Task to do choose different values for batch size (minimum five different values)\n",
        "BATCH_SIZE = [8,16,32,64,128] # Choose a value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1CVvMthBmWr"
      },
      "source": [
        "## Do not change anything below\n",
        "model = built_model(INPUT_SHAPE,128, NB_CLASSES)\n",
        "history = model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=50,\n",
        "\t\tverbose=1, validation_split=0.2)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy: {:.2f} %'.format(test_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CT-1vk1AbK5",
        "outputId": "b15d52ce-76cb-4e3b-e6c0-58e88481d81e"
      },
      "source": [
        "for i in range(0,len(BATCH_SIZE)):\n",
        "  model = built_model(INPUT_SHAPE,128, NB_CLASSES)\n",
        "  history = model.fit(X_train, Y_train,\n",
        "\t\t  batch_size=BATCH_SIZE[i], epochs=50,\n",
        "\t\t  verbose=0, validation_split=0.2)\n",
        "  # Evaluate the model\n",
        "  test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "  print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9791\n",
            "0.9790999889373779\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0799 - accuracy: 0.9788\n",
            "0.9787999987602234\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0839 - accuracy: 0.9738\n",
            "0.973800003528595\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.9728\n",
            "0.9728000164031982\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1195 - accuracy: 0.9662\n",
            "0.9661999940872192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGBwMAO1EW7d"
      },
      "source": [
        "There were no big differences using different values ​​in the BATCH_SIZE parameter. As this parameter increased, the accuracy decreased slightly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L802oqkCBg8"
      },
      "source": [
        "<a id='ex_5'></a>\n",
        "### Part 5: Hyperparameters\n",
        "\n",
        "**Exercise 5:** And now we do the same with different [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) available in TensorFlow. Change the optimizers and compare the model performance in terms of accuracy. What do you understand from this?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DsZiC8CB7j5"
      },
      "source": [
        "# Task to do choose different optimizers\n",
        "opt = ['sgd','adam']# Choose from available optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X4HBlOhExCV",
        "outputId": "f22993e3-d687-4ec0-b415-26501e257d8a"
      },
      "source": [
        "## Do not change anything below\n",
        "for i in range(0,len(opt)):\n",
        "  model = built_model(INPUT_SHAPE,128, NB_CLASSES, opt[i])\n",
        "  history = model.fit(X_train, Y_train,\n",
        "\t\t  batch_size=128, epochs=50,\n",
        "\t\t  verbose=0, validation_split=0.2)\n",
        "  # Evaluate the model\n",
        "  test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "  print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1239 - accuracy: 0.9635\n",
            "0.9635000228881836\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1264 - accuracy: 0.9808\n",
            "0.9807999730110168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-46TwuMnDdIB"
      },
      "source": [
        "<a id='ex_O'></a>\n",
        "### Optional Exercise: Fashion MNIST\n",
        "\n",
        "Let's use a different input. You can use Fashion MNIST another popular ML dataset. Are the results same?.\n",
        "\n",
        "To download fashion mnist you can use the following code:\n",
        "\n",
        "```\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmqnMehiN1Yn",
        "outputId": "ea76f37b-1dc7-4c0c-ccfc-33ec43aea9df"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        " \n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqc0ID8XDLCN"
      },
      "source": [
        "# Processing the data\n",
        "assert(len(X_train.shape)==3), \"The input data is not of the right shape\"\n",
        "RESHAPED = X_train.shape[1]*X_train.shape[2]\n",
        "\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pglk3gtxN3tN",
        "outputId": "ffb4854b-a3e2-4e8a-ef6f-7e9bbda414d7"
      },
      "source": [
        "# Data Normalization\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGLJgxssN71p"
      },
      "source": [
        "INPUT_SHAPE = RESHAPED\n",
        "NB_CLASSES = len(set(Y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82YynkDtODle"
      },
      "source": [
        "# one-hot encode\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJZerDNWOG4W"
      },
      "source": [
        "N_HIDDEN = [10,20,30,40,50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bryFZZhOR_A",
        "outputId": "b2ea4b36-1524-4660-ec75-9094ca3b7649"
      },
      "source": [
        "## Do not change anything below\n",
        "for i in range(0,len(N_HIDDEN)):\n",
        "  model = built_model(INPUT_SHAPE,N_HIDDEN[i], NB_CLASSES)\n",
        "  history = model.fit(X_train, Y_train,\n",
        "\t\t  batch_size=128, epochs=50,\n",
        "\t\t  verbose=0, validation_split=0.2)\n",
        "  # Evaluate the model\n",
        "  test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "  print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.8429\n",
            "0.8428999781608582\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4230 - accuracy: 0.8515\n",
            "0.8514999747276306\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4228 - accuracy: 0.8521\n",
            "0.8521000146865845\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4029 - accuracy: 0.8564\n",
            "0.8564000129699707\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8610\n",
            "0.8610000014305115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iap-wPBVPJKa"
      },
      "source": [
        "When comparing different numbers of neurons for this new data set, it is seen that the accuracy decreased compared to the results obtained with the previous data set."
      ]
    }
  ]
}